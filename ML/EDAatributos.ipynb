{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## En el siguiente Notebook se encuentra todo el codigo ejecutado para obtener el dataset final para el modelo ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "from fuzzywuzzy import fuzz,process\n",
    "import functools"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se Importan los dataset para el inicio del filtrado y exploracion de los datos** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../dataset.csv\", low_memory=False)\n",
    "test = pd.read_csv(\"../ciudades_categorias.csv\", low_memory=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se doprean las columnas innecesarias para este modelo**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas columnas no representan ningun valor para este segundo modelo el cual va a concentrar su entrenamientos en la columana de atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"name\",axis=\"columns\",inplace=True)\n",
    "df.drop(\"city\",axis=\"columns\",inplace=True)\n",
    "df.drop(\"review_count\",axis=\"columns\",inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Se categorizan variables para optimizar el dataset de entrada*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"categoria\"] = pd.Categorical(df[\"categoria\"]).codes\n",
    "df[\"state\"] = pd.Categorical(df[\"state\"]).codes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ahora se comienza a dropear nulos y esatandarizar categorias y atributos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"atributos\"], inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"atributos\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"categoria\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catunique =[]\n",
    "catunique = test[\"NDescripcion\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(catunique)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*La siguiente función ayuda a filtrar categorias repetidas o de mismo valor a partir de la lista generada previamente*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_umbral_similitud(longitud_ciudad):\n",
    "    umbral_base = 70\n",
    "    umbral = umbral_base - (longitud_ciudad // 4)\n",
    "    return max(umbral, umbral_base)\n",
    "\n",
    "@functools.lru_cache(maxsize=None)\n",
    "def encontrar_mejor_coincidencia(ciudad):\n",
    "    mejor_coincidencia = process.extractOne(ciudad, catunique)\n",
    "    resultado = mejor_coincidencia[0] if mejor_coincidencia[1] >= calcular_umbral_similitud(len(ciudad)) else ciudad\n",
    "    return resultado"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Se convierten los valores para poder ser procesados por la función*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['categoria'] = df['categoria'].astype(str)\n",
    "df[\"categoria\"] = df[\"categoria\"].str.lstrip()\n",
    "df[\"categorias_filtradas\"] = df[\"categoria\"].apply(encontrar_mejor_coincidencia)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente filtro permite visualizar las primeras 169 categorias con mas coincidencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"categorias_filtradas\"].value_counts(ascending=False).head(169)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se filtra la nueva columna filtrada por las primeras 169 categorias con mejor coincidencia para luego ser reemplazos los valores de la columna original \"categoria\". Posteriormente, se dropea la columna generada. (Esto se hizo para comparar los valores de cada columna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_categorias = df[\"categorias_filtradas\"].value_counts(ascending=False).head(169).index.tolist()\n",
    "df = df[df[\"categorias_filtradas\"].isin(top_categorias)]\n",
    "df[\"categoria\"] = df[\"categorias_filtradas\"]\n",
    "df.drop(\"categorias_filtradas\",axis=\"columns\",inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se controla la cantidad de categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"categoria\"].nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A patir de aca, se empieza a limpiar los atributos que no hacen un aporte significativo a la muestra y la optimizacion y nomralizacion de los parametros de entrada en la columna \"atributos\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aca se filtran los valores que contengan \":\" dos veces\n",
    "atributos = df['atributos']\n",
    "atributos_con_u = [atributo for atributo in atributos if isinstance(atributo, str) and atributo.split(':')[1].strip().startswith('u')]\n",
    "for atributo in atributos_con_u:\n",
    "    print(atributo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aca se filtran los valores que contengan \"u\" despues de los \":\"\n",
    "atributos_filtrados = []\n",
    "\n",
    "for atributo in atributos:\n",
    "    if isinstance(atributo, str):\n",
    "        partes = atributo.split(':')\n",
    "        if len(partes) == 2: \n",
    "            clave = partes[0].strip()\n",
    "            valor = partes[1].strip().lstrip('u')\n",
    "            atributos_filtrados.append(f'{clave}: {valor}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se crea una funcion de limpieza para atributos que burlaron el filtro anterior \n",
    "def limpiar_atributo(atributo):\n",
    "    if isinstance(atributo, str):\n",
    "        partes = atributo.split(':')\n",
    "        if len(partes) == 2:\n",
    "            clave = partes[0].strip()\n",
    "            valor = partes[1].strip().lstrip('u')\n",
    "            return f'{clave}: {valor}'\n",
    "    return atributo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['atributos'] = df['atributos'].apply(limpiar_atributo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se crea una funcion de limpieza para atributos que contienen un espacio vacio o caracteres desconocidos\n",
    "def limpiar_atributo2(atributo):\n",
    "    if isinstance(atributo, str):\n",
    "        atributo_limpio = re.sub(r':\\su\\w+', '', atributo)\n",
    "        return atributo_limpio.strip()\n",
    "    return atributo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['atributos'] = df['atributos'].apply(limpiar_atributo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se vuelve a correr el filtro como medida final debido a atributos que aparecian de nuevo\n",
    "atributos = df['atributos']\n",
    "atributos_con_u = [atributo for atributo in atributos if isinstance(atributo, str) and atributo.split(':')[1].strip().startswith('u')]\n",
    "for atributo in atributos_con_u:\n",
    "    print(atributo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esta operacion controla la existencia de valores que hayan podido saltar los filtros de limpieza\n",
    "suma = sum(float(atributo.split(':')[1].strip()) for atributo in atributos_con_u if atributo.split(':')[1].strip().isdigit())\n",
    "suma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print de control\n",
    "print(df['atributos'].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se agrega un ultimo filtro endswitch para eliminar definitivamente los \"False\"\n",
    "df = df[~df['atributos'].str.endswith('False')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se agrega un ultimo filtro endswitch para eliminar definitivamente los \"False\"\n",
    "consulta = df[df['atributos'].apply(lambda x: str(x).endswith(\"False\"))]\n",
    "consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se agrega un ultimo filtro endswitch para eliminar definitivamente los espacios vacios \n",
    "df = df[~df['atributos'].str.contains(': None$|:$', regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Head de control\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se controla la cantidad final de categorias para coincidir con el modelo de raiting antes de su entrenamiento\n",
    "df[\"categoria\"].nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se exporta el dataset limpio para su entrenamiento (comentar/descomentar despues de usar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"dataset2.csv\", index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
