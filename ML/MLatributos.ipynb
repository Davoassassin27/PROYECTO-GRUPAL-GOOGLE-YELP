{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informe del modelo de clasificación con redes neuronales\n",
    "\n",
    "Este informe detalla el proceso y los resultados de un modelo de clasificación implementado utilizando redes neuronales con la biblioteca Keras. El objetivo del modelo es predecir las etiquetas de atributos a partir de características como la calificación (stars), la categoría (categoria) y el estado (state) de un conjunto de datos.\n",
    "\n",
    "## 1. Preprocesamiento de los datos\n",
    "\n",
    "En esta etapa, se realiza el preprocesamiento de los datos de entrada para prepararlos adecuadamente para el entrenamiento del modelo. Las siguientes acciones se llevan a cabo:\n",
    "\n",
    "### 1.1. Selección de características\n",
    "\n",
    "Se seleccionan las características relevantes para el modelo, que son la calificación (stars), la categoría (categoria) y el estado (state). Estas características se extraen del DataFrame original `df` y se almacenan en el DataFrame `X`.\n",
    "\n",
    "### 1.2. Codificación de variables categóricas\n",
    "\n",
    "Para poder utilizar las variables categóricas en el modelo, se realiza una codificación mediante la técnica de \"one-hot encoding\". Esto implica convertir las variables categóricas en variables numéricas binarias. En este caso, se aplica `pd.get_dummies(X)` para codificar las variables categóricas en columnas binarias correspondientes a cada categoría.\n",
    "\n",
    "### 1.3. Codificación de etiquetas\n",
    "\n",
    "Las etiquetas de atributos (y) se codifican utilizando el codificador de etiquetas (`LabelEncoder()`) de la biblioteca scikit-learn. Esto asigna un valor numérico a cada etiqueta de atributo, lo cual es necesario para el entrenamiento del modelo. Las etiquetas codificadas se almacenan en la variable `y_train_encoded`.\n",
    "\n",
    "## 2. División del conjunto de datos\n",
    "\n",
    "El conjunto de datos se divide en conjuntos de entrenamiento y prueba para evaluar el rendimiento del modelo. Se utiliza la función `train_test_split()` de scikit-learn para dividir los datos codificados (`X`) y las etiquetas codificadas (`y_train_encoded`) en conjuntos de entrenamiento (`X_train`, `y_train`) y prueba (`X_test`, `y_test`). En este caso, se asigna el 25% de los datos al conjunto de prueba y se utiliza una semilla aleatoria (`random_state`) para garantizar la reproducibilidad de los resultados.\n",
    "\n",
    "## 3. Definición del modelo\n",
    "\n",
    "El modelo se define como una secuencia de capas utilizando la API `Sequential` de Keras. El modelo consta de tres capas densas (totalmente conectadas) con funciones de activación ReLU, seguidas de una capa de salida con una función de activación softmax. La capa de entrada tiene una dimensión igual al número de características en los datos de entrenamiento (`X_train.shape[1]`), y la capa de salida tiene una dimensión igual al número máximo de etiquetas codificadas (`np.max(y_train) + 1`).\n",
    "\n",
    "## 4. Compilación y entrenamiento del modelo\n",
    "\n",
    "Antes de entrenar el modelo, se debe compilar especificando la función de pérdida (`loss`), el optimizador (`optimizer`) y las métricas que se utilizarán para evaluar el rendimiento del modelo (`metrics`). En este caso, se utiliza la función de pérdida `sparse_categorical_crossentropy` adecuada para problemas de clasificación con múltiples clases. El optimizador seleccionado es `adam`, que es un algoritmo de optimización popular en el aprendizaje profundo.\n",
    "\n",
    "A continuación, se entrena el modelo utilizando el conjunto de entrenamiento (`X_train`, `y_train`) durante un número determinado de épocas (`epochs`) y un tamaño de lote (`batch_size`). Además, se utiliza una validación cruzada del 20% del conjunto de entrenamiento (`validation_split`) para monitorear el rendimiento del modelo durante el entrenamiento y evitar el sobreajuste.\n",
    "\n",
    "## 5. Evaluación del modelo\n",
    "\n",
    "Una vez finalizado el entrenamiento, se evalúa el rendimiento del modelo utilizando el conjunto de prueba (`X_test`, `y_test`). Se calcula la pérdida (`test_loss`) y la precisión (`test_acc`) del modelo en este conjunto de datos.\n",
    "\n",
    "## 6. Predicciones\n",
    "\n",
    "Se utilizan las características codificadas del conjunto de prueba (`X_test`) para realizar predicciones con el modelo entrenado. Las predicciones se almacenan en la variable `predictions` y representan las probabilidades de pertenencia a cada clase de atributo.\n",
    "\n",
    "---\n",
    "\n",
    "Este informe describe el proceso de construcción, entrenamiento y evaluación de un modelo de clasificación utilizando redes neuronales. El modelo utiliza las características de calificación, categoría y estado para predecir las etiquetas de atributos. Los resultados obtenidos se basan en las métricas de pérdida y precisión del modelo en el conjunto de prueba.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora si, el código... ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import mtranslate as mt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se importan librerias y se carga el dataframe listo para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset2.csv\", low_memory=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crean variables y la red neuronal + el entrenamiento y testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "9110/9110 [==============================] - 41s 4ms/step - loss: 3.9026 - accuracy: 0.0846 - val_loss: 3.6592 - val_accuracy: 0.0877\n",
      "Epoch 2/15\n",
      "9110/9110 [==============================] - 40s 4ms/step - loss: 3.6652 - accuracy: 0.0876 - val_loss: 3.6612 - val_accuracy: 0.0878\n",
      "Epoch 3/15\n",
      "9110/9110 [==============================] - 44s 5ms/step - loss: 3.6605 - accuracy: 0.0875 - val_loss: 3.6927 - val_accuracy: 0.0877\n",
      "Epoch 4/15\n",
      "9110/9110 [==============================] - 43s 5ms/step - loss: 3.6576 - accuracy: 0.0875 - val_loss: 3.6587 - val_accuracy: 0.0875\n",
      "Epoch 5/15\n",
      "9110/9110 [==============================] - 44s 5ms/step - loss: 3.6550 - accuracy: 0.0874 - val_loss: 3.6533 - val_accuracy: 0.0875\n",
      "Epoch 6/15\n",
      "9110/9110 [==============================] - 40s 4ms/step - loss: 3.6524 - accuracy: 0.0874 - val_loss: 3.6487 - val_accuracy: 0.0877\n",
      "Epoch 7/15\n",
      "9110/9110 [==============================] - 37s 4ms/step - loss: 3.6493 - accuracy: 0.0873 - val_loss: 3.6572 - val_accuracy: 0.0875\n",
      "Epoch 8/15\n",
      "9110/9110 [==============================] - 36s 4ms/step - loss: 3.6465 - accuracy: 0.0873 - val_loss: 3.6502 - val_accuracy: 0.0858\n",
      "Epoch 9/15\n",
      "9110/9110 [==============================] - 37s 4ms/step - loss: 3.6433 - accuracy: 0.0872 - val_loss: 3.6411 - val_accuracy: 0.0855\n",
      "Epoch 10/15\n",
      "9110/9110 [==============================] - 43s 5ms/step - loss: 3.6354 - accuracy: 0.0872 - val_loss: 3.6354 - val_accuracy: 0.0876\n",
      "Epoch 11/15\n",
      "9110/9110 [==============================] - 49s 5ms/step - loss: 3.6297 - accuracy: 0.0875 - val_loss: 3.6289 - val_accuracy: 0.0875\n",
      "Epoch 12/15\n",
      "9110/9110 [==============================] - 44s 5ms/step - loss: 3.6267 - accuracy: 0.0877 - val_loss: 3.6231 - val_accuracy: 0.0876\n",
      "Epoch 13/15\n",
      "9110/9110 [==============================] - 45s 5ms/step - loss: 3.6246 - accuracy: 0.0876 - val_loss: 3.6225 - val_accuracy: 0.0877\n",
      "Epoch 14/15\n",
      "9110/9110 [==============================] - 42s 5ms/step - loss: 3.6219 - accuracy: 0.0879 - val_loss: 3.6211 - val_accuracy: 0.0878\n",
      "Epoch 15/15\n",
      "9110/9110 [==============================] - 40s 4ms/step - loss: 3.6196 - accuracy: 0.0879 - val_loss: 3.6147 - val_accuracy: 0.0880\n",
      "11861/11861 [==============================] - 29s 2ms/step - loss: 3.6178 - accuracy: 0.0876\n",
      "Precisión en el conjunto de prueba: 0.08761141449213028\n",
      "11861/11861 [==============================] - 25s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "X = df[['stars', 'categoria', 'state']]\n",
    "y = df['atributos']\n",
    "\n",
    "# filtered_indices = (y != 'AcceptsInsurance: None')\n",
    "# X = X[filtered_indices]\n",
    "# y = y[filtered_indices]\n",
    "\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y)\n",
    "y_train_encoded = y_train_encoded.astype(np.float32)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_train_encoded, test_size=0.25, random_state=42)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(np.max(y_train) + 1, activation='softmax') \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=15, batch_size=100, validation_split=0.2)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Precisión en el conjunto de prueba: {test_acc}')\n",
    "\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardado del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: modelo_at_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: modelo_at_1\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('modelo_at_1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se crean funciones para ejecutar consultas tanto con el dataset original, en inglés, como en español y con la cantidad deseada de atributos a visualizar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hacer_predicciones(modelo, datos_nuevos, top_n=5):\n",
    "    datos_codificados = pd.get_dummies(datos_nuevos[['stars', 'categoria', 'state']])\n",
    "    predicciones = modelo.predict(datos_codificados)\n",
    "    top_clases = np.argsort(-predicciones)[:, :top_n]\n",
    "    etiquetas_predichas = []\n",
    "    \n",
    "    for ejemplo in top_clases:\n",
    "        atributos = label_encoder.inverse_transform(ejemplo)\n",
    "        atributos_divididos = [re.sub(r'(?<!^)(?=[A-Z])', ' ', attr.split(': ')[0]) + ': ' + attr.split(': ')[1] for attr in atributos]\n",
    "        atributos_traducidos = [mt.translate(attr, \"es\", \"en\") for attr in atributos_divididos]\n",
    "        etiquetas_predichas.append(atributos_traducidos)\n",
    "    \n",
    "    return etiquetas_predichas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hacer_predicciones2(modelo, datos_nuevos, top_n=5):\n",
    "    datos_codificados = pd.get_dummies(datos_nuevos[['stars', 'categoria', 'state']])\n",
    "    predicciones = modelo.predict(datos_codificados)\n",
    "    top_clases = np.argsort(-predicciones)[:, :top_n]\n",
    "    etiquetas_predichas = []\n",
    "    \n",
    "    for ejemplo in top_clases:\n",
    "        etiquetas_predichas.append(label_encoder.inverse_transform(ejemplo))\n",
    "    \n",
    "    return list(etiquetas_predichas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hacer_predicciones3(modelo, datos_nuevos, top_n=5):\n",
    "    datos_codificados = pd.get_dummies(datos_nuevos[['stars', 'categoria', 'state']])\n",
    "    predicciones = modelo.predict(datos_codificados)\n",
    "    top_clases = np.argsort(-predicciones)[:, :top_n]\n",
    "    etiquetas_predichas = []\n",
    "    \n",
    "    for ejemplo in top_clases:\n",
    "        atributos = label_encoder.inverse_transform(ejemplo)\n",
    "        atributos_divididos = [attr.split(':')[0] for attr in atributos if ':' in attr]\n",
    "        atributos_traducidos = [mt.translate(attr, \"es\", \"en\") for attr in atributos_divididos]\n",
    "        etiquetas_predichas.append(atributos_traducidos)\n",
    "    \n",
    "    return etiquetas_predichas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hacer_predicciones4(modelo, datos_nuevos, top_n=10):\n",
    "    datos_codificados = pd.get_dummies(datos_nuevos[['stars', 'categoria', 'state']])\n",
    "    predicciones = modelo.predict(datos_codificados)\n",
    "    top_clases = np.argsort(-predicciones)[:, :top_n]\n",
    "    etiquetas_predichas = []\n",
    "    \n",
    "    for ejemplo in top_clases:\n",
    "        atributos = label_encoder.inverse_transform(ejemplo)\n",
    "        atributos_divididos = [re.sub(r'(?<!^)(?=[A-Z])', ' ', attr.split(': ')[0]) + ': ' + attr.split(': ')[1] for attr in atributos]\n",
    "        atributos_traducidos = [mt.translate(attr, \"es\", \"en\") for attr in atributos_divididos]\n",
    "        etiquetas_predichas.append(atributos_traducidos)\n",
    "    \n",
    "    return etiquetas_predichas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hacer_predicciones5(modelo, datos_nuevos, top_n=5):\n",
    "    datos_codificados = pd.get_dummies(datos_nuevos[['stars', 'categoria', 'state']])\n",
    "    predicciones = modelo.predict(datos_codificados)\n",
    "    top_clases = np.argsort(-predicciones)[:, :top_n]\n",
    "    etiquetas_predichas = []\n",
    "    \n",
    "    for ejemplo in top_clases:\n",
    "        atributos = label_encoder.inverse_transform(ejemplo)\n",
    "        atributos_divididos = []\n",
    "        \n",
    "        for attr in atributos:\n",
    "            if ':' in attr and 'Verdadero' not in attr:\n",
    "                attr_dividido = attr.split(':')[0]\n",
    "                atributos_divididos.append(attr_dividido)\n",
    "        \n",
    "        atributos_traducidos = [mt.translate(attr, \"es\", \"en\") for attr in atributos_divididos]\n",
    "        etiquetas_predichas.append(atributos_traducidos)\n",
    "    \n",
    "    return etiquetas_predichas\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*El labelEconder de abajo sirve para ejecutar solo cuando el modelo ya esta cargado y no se quiere volver a entrenar para declarar la variable (ojo, sino las funciones pueden arrojar errores!)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label_encoder = LabelEncoder()\n",
    "# label_encoder.fit(df['atributos'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Algunas consultas...** ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 162ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Rango de precios de restaurantes2: 3',\n",
       "  'El negocio acepta tarjetas de crédito: verdadero',\n",
       "  'Restaurantes Rango de precios2: 2',\n",
       "  'Estacionamiento de bicicletas: verdadero',\n",
       "  'Estacionamiento comercial en la calle: Verdadero']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_cargado = keras.models.load_model('modelo_at_1')\n",
    "nuevos_datos = pd.DataFrame({'stars': [2], 'categoria': ['Restaurante'], 'state': ['California']})\n",
    "etiquetas_predichas = hacer_predicciones(modelo_cargado, nuevos_datos, top_n=5)\n",
    "etiquetas_predichas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 134ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['NegocioAceptaCréditoTarjetas',\n",
       "  'Solo por cita',\n",
       "  'Calle de estacionamiento de negocios',\n",
       "  'BicicletaAparcamiento',\n",
       "  'Silla de ruedas accesible']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_cargado = keras.models.load_model('modelo_at_1')\n",
    "nuevos_datos = pd.DataFrame({'stars': [4], 'categoria': ['Restaurante'], 'state': ['California']})\n",
    "etiquetas_predichas = hacer_predicciones3(modelo_cargado, nuevos_datos, top_n=5)\n",
    "etiquetas_predichas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 67ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Rango de precios de restaurantes2: 3',\n",
       "  'El negocio acepta tarjetas de crédito: verdadero',\n",
       "  'Restaurantes Rango de precios2: 2',\n",
       "  'Estacionamiento de bicicletas: verdadero',\n",
       "  'Estacionamiento comercial en la calle: Verdadero',\n",
       "  'Estacionamiento comercial: verdadero',\n",
       "  'Restaurantes Rango de precios2: 4',\n",
       "  'Rango de precios de restaurantes2: 1',\n",
       "  'Accesible para sillas de ruedas: Verdadero',\n",
       "  'Estacionamiento comercial: garaje']]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_cargado = keras.models.load_model('modelo_at_1')\n",
    "nuevos_datos = pd.DataFrame({'stars': [2], 'categoria': ['Restaurante'], 'state': ['California']})\n",
    "etiquetas_predichas = hacer_predicciones(modelo_cargado, nuevos_datos, top_n=10)\n",
    "etiquetas_predichas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*¡Hasta Aqui la red neuronal!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
